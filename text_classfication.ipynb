{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "57361283-919d-4426-a19c-22662f42cd36"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rle0502/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d9063a45-46c7-4476-b3ae-d8284718c793"
    }
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0bed47c7-4582-40d9-8872-5d3881ee98b9"
    }
   },
   "source": [
    "##### The load files  function will loop through all the different directories contained in the given folder, and for each of the different subdirectories contained in this directory it will generate 2 classes so for neg folder it will generate a class 0 and for pos it will generate a class 1.\n",
    "##### It will put all the files from the neg as class 0 and all the pos files as class 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "79c9b267-9198-4b2d-8b8c-eba49217634a"
    }
   },
   "outputs": [],
   "source": [
    "#Importing our review datasets\n",
    "reviews = load_files('txt_sentoken/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "a2b90de0-a0b1-4d12-b31e-f0a21d0f780b"
    }
   },
   "outputs": [],
   "source": [
    "#Next will seperate the data and class from the reviews\n",
    "X,y = reviews.data, reviews.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a36b8584-d1ae-49db-83e1-dc4a7f8dd2b6"
    }
   },
   "source": [
    "## Persisiting datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b404467e-1d68-4ec5-aaef-5083a9d167f2"
    }
   },
   "source": [
    "#### This load_files function will be slower in case of the data is very large, hence to make this process faster we store the X and y as the pickle files which are byte type files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "dfd89122-57f8-4463-b16a-87fb87f935af"
    }
   },
   "outputs": [],
   "source": [
    "#Storing as pickle files\n",
    "with open('X.pickle','wb') as f:\n",
    "    pickle.dump(X,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "74c65957-56aa-4d75-8bf5-7e87f93f153e"
    }
   },
   "outputs": [],
   "source": [
    "with open('y.pickle', 'wb') as f:\n",
    "    pickle.dump(y,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5fbb982c-2ebc-4c85-830f-34f03ff10dcd"
    }
   },
   "outputs": [],
   "source": [
    "#To unpickle the loaded data\n",
    "with open('X.pickle', 'rb') as f:\n",
    "    X = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "7fe9906a-2795-4494-acfd-6498abc22c72"
    }
   },
   "outputs": [],
   "source": [
    "with open('y.pickle', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6c06c934-ab87-4358-80a7-09c2538992fe"
    }
   },
   "source": [
    "## Prerocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "196aeb49-5a2f-4a83-821e-ce94f4cc99cf"
    }
   },
   "source": [
    "##### We will create a corpus list of documents) list which  will contain all the preprocessed documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "762cc9fb-fab1-46b3-9176-d55c0f0efaf3"
    }
   },
   "outputs": [],
   "source": [
    "#Creating the corpus\n",
    "corpus = []\n",
    "for i in range(0, len(X)):\n",
    "    #Removing all the punctuation and special characters\n",
    "    review = re.sub(r'\\W', ' ', str(X[i]))\n",
    "    review = review.lower()\n",
    "    #Removing single character as they are not important for text classfication\n",
    "    review = re.sub(r'\\s+[a-z]\\s+', ' ',review)\n",
    "    review = re.sub(r'^[a-z]\\s+', ' ',review)\n",
    "    #Removing extra spaces from the begining of the sentence\n",
    "    review = re.sub(r'\\s+', ' ', review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e3671882-2fff-47b0-9818-aba6a40f57ec"
    }
   },
   "source": [
    "## Transforming data into Bag of words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "047ad2b7-0c7b-4a54-998a-488f83e9c900"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "4b9c395d-0f79-4ee5-9c0f-574ad88c82b3"
    }
   },
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer(max_features=3000, min_df=3, max_df= 0.6, stop_words=stopwords.words('english'))\n",
    "# #Bag of words model\n",
    "# X = vectorizer.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f52d2348-30d5-4627-a0f8-ed9e6b3b9460"
    }
   },
   "source": [
    "## Transforming bag of words model into TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "afe6756e-4723-46fe-a0a4-9a8b93abd881"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "eaafeec3-7966-4c15-9022-a1692f812a56"
    }
   },
   "outputs": [],
   "source": [
    "# transformer = TfidfTransformer()\n",
    "# X = transformer.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=2000, min_df=3, max_df= 0.6, stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "07b70965-0618-4418-b4df-970bd163c4ec"
    }
   },
   "source": [
    "## Creating Training Set and Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "545fbaf2-b811-49c0-9ea4-7916bf6f0c60"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "7450a1c2-e162-4b3f-909d-413227a59465"
    }
   },
   "outputs": [],
   "source": [
    "text_train, test_train, sent_train, sent_test=train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(text_train, sent_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent_pred = classifier.predict(test_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(sent_test, sent_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[158,  32],\n",
       "       [ 34, 176]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ascore = accuracy_score(sent_test, sent_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.835"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ascore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pickling the classifier\n",
    "# We need to save both the classifier and vectorizer for making future prediction\n",
    "with open('classifier.pickle','wb') as f:\n",
    "    pickle.dump(classifier,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('tfidfmode.pickle', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and using our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('classifier.pickle', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('tfidfmode.pickle', 'rb') as f:\n",
    "    tfidf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = [\"You are very bad person\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = tfidf.transform(sample).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "nbpresent": {
   "slides": {
    "6f1b219c-cd50-4ccf-a951-3af28c7fc366": {
     "id": "6f1b219c-cd50-4ccf-a951-3af28c7fc366",
     "prev": null,
     "regions": {
      "38688263-73b5-410f-afcd-7a7190db0f09": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "57361283-919d-4426-a19c-22662f42cd36",
        "part": "whole"
       },
       "id": "38688263-73b5-410f-afcd-7a7190db0f09"
      }
     }
    },
    "f1955f00-48f7-4e92-8b11-661aa68dbdf4": {
     "id": "f1955f00-48f7-4e92-8b11-661aa68dbdf4",
     "prev": "6f1b219c-cd50-4ccf-a951-3af28c7fc366",
     "regions": {
      "24cad125-5e6f-4089-827b-46806d2c0ada": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "id": "24cad125-5e6f-4089-827b-46806d2c0ada"
      }
     }
    }
   },
   "themes": {
    "default": "a15b28e4-a20d-4020-bc0e-e3a1f14f5ea0",
    "theme": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
